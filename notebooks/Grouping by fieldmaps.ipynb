{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping scans by fieldmaps and phase encoding directions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\n",
      "dataset_description.json\n",
      "sub-tester\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x DSCSDSI_BUDS/\n",
      "x DSCSDSI_BUDS/sub-tester/\n",
      "x DSCSDSI_BUDS/sub-tester/fmap/\n",
      "x DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-AP_epi.json\n",
      "x DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-AP_epi.nii.gz\n",
      "x DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-PA_epi.json\n",
      "x DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-PA_epi.nii.gz\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.bval\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.json\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.bvec\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.bval\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.nii.gz\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.nii.gz\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.bvec\n",
      "x DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.json\n",
      "x DSCSDSI_BUDS/sub-tester/anat/\n",
      "x DSCSDSI_BUDS/sub-tester/anat/sub-tester_T1w.nii.gz\n",
      "x DSCSDSI_BUDS/sub-tester/anat/sub-tester_T1w.json\n",
      "x DSCSDSI_BUDS/dataset_description.json\n",
      "x DSCSDSI_BUDS/README\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "SAMPLE_URL=\"https://upenn.box.com/shared/static/bvhs3sw2swdkdyekpjhnrhvz89x3k87t.xz\"\n",
    "wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \\\n",
    " -O dscsdsi_buds.tar.xz ${SAMPLE_URL}\n",
    " \n",
    "tar xvfJ dscsdsi_buds.tar.xz\n",
    "ls DSCSDSI_BUDS\n",
    "rm dscsdsi_buds.tar.xz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIDS Layout: ...qsiprep/notebooks/DSCSDSI_BUDS | Subjects: 1 | Sessions: 0 | Runs: 0\n",
      "Combining all 2 dwis within the single available session\n",
      "[['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.nii.gz', '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.nii.gz']]\n"
     ]
    }
   ],
   "source": [
    "from qsiprep.utils.bids import collect_data\n",
    "\n",
    "def get_session_groups(layout, subject_data, combine_all_dwis):\n",
    "    # Handle the grouping of multiple dwi files within a session\n",
    "    sessions = layout.get_sessions() if layout is not None else []\n",
    "    all_dwis = subject_data['dwi']\n",
    "    dwi_session_groups = []\n",
    "    if not combine_all_dwis:\n",
    "        dwi_session_groups = [[dwi] for dwi in all_dwis]\n",
    "    else:\n",
    "        if sessions:\n",
    "            print('Combining all dwi files within each available session:')\n",
    "            for session in sessions:\n",
    "                session_files = [img for img in all_dwis if 'ses-'+session in img]\n",
    "                print('\\t- %d sessions in %s', len(session_files), session)\n",
    "                dwi_session_groups.append(session_files)\n",
    "        else:\n",
    "            print(\n",
    "                'Combining all %d dwis within the single available session' % len(all_dwis))\n",
    "            dwi_session_groups = [all_dwis]\n",
    "    return dwi_session_groups\n",
    "\n",
    "subject_data, layout = collect_data(\"DSCSDSI_BUDS\", \"tester\")\n",
    "print(layout)\n",
    "\n",
    "# Handle the grouping of multiple dwi files within a session\n",
    "dwi_session_groups = get_session_groups(layout, subject_data, combine_all_dwis=True)\n",
    "print(dwi_session_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of both files because combine_all_dwis is true. How these are combined depends on whether they should be combined in a blip-up/blip-down series (BUDS) or whether they should be corrected using their fieldmaps.\n",
    "\n",
    "```python\n",
    "for dwi_session_group in dwi_session_groups:\n",
    "    dwi_fmap_groups.extend(\n",
    "        group_by_fieldmaps(dwi_session_group, layout,\n",
    "                           \"fieldmaps\" in ignore or force_syn,\n",
    "                           prefer_dedicated_fmaps,\n",
    "                           combine_all_dwis))\n",
    "```\n",
    "\n",
    "Instead we will walk though the `group_by_fieldmaps` function to show how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# There is only one group so don't loop\n",
    "dwi_files = dwi_session_groups[0]\n",
    "\n",
    "def group_by_fieldmaps(dwi_files, layout, ignore_fieldmap, prefer_dedicated_fmaps,\n",
    "                       combine_all_dwis):\n",
    "    \"\"\"Groups a session's DWI files by their PE direction and fieldmaps, if specified.\n",
    "    \n",
    "    DWIs are grouped by their **warped space**. Two DWI series that are \n",
    "    listed in the IntendedFor field of a fieldmap are assumed to have the same \n",
    "    susceptibility distortions and therefore be in the same warped space. The goal \n",
    "    of this function is to combine DWI series into groups of acquisitions that \n",
    "    are in the same warped space into a list of scans that can be combined after\n",
    "    unwarping. \n",
    "    \n",
    "    The first step in the pipeline must be ``dwidenoise``. This algorithm can \n",
    "    be run directly on each DWI Series. OR, DWI series in the same warped space \n",
    "    can be combined before running ``dwidenoise``.  Running ``dwidenoise`` on \n",
    "    concatenated DWI series that include noise and susceptibility distortion \n",
    "    violates the assumptions made by ``dwidenoise`` and is not allowed. \n",
    "    Performing susceptibility distortion correction before running ``dwidenoise``\n",
    "    is also not allowed.\n",
    "    \n",
    "    Similarly, SHORELine performs head motion correction in **warped space**.\n",
    "    The more q-space samples are available to SHORELine, the better the EAP\n",
    "    estimates. However, if the position of the head is very different between\n",
    "    the two runs it may take more iterations for SHORELine to converge. Be sure \n",
    "    to check the QC files if using this algorithm.\n",
    "    \n",
    "    Specifying ``combine_all_dwis=True`` means that the SDC outputs will be \n",
    "    used to combine across warped spaces. If ``False``, then no scans will be \n",
    "    combined even if they are in the same warped space. Other \n",
    "    possibilities for grouping are not supported.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    \n",
    "        dwi_files: list\n",
    "            A list of full paths to dwi nifti files in a BIDS tree\n",
    "        \n",
    "        layout: BIDSLayout\n",
    "            A representation of the BIDS tree\n",
    "            \n",
    "        prefer_dedicated_fmaps: bool\n",
    "            If True, use files in fmap directories to perform SDC even if there \n",
    "            is a series in dwi with the reverse phase encoding direction that \n",
    "            could be used.\n",
    "            \n",
    "        combine_all_dwis: bool\n",
    "            If True, concaenate DWI series that can be concatenated. To be concatenated\n",
    "            the series must either have the same phase encoding direction or there \n",
    "            must be fieldmaps that correct for opposite phase encoding directions.\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    \n",
    "        groups_list: list\n",
    "            A list of dictionaries that describe \"group info\". These can take a couple forms\n",
    "            \n",
    "            When there are two groups of dwi series with opposite phase encoding dirs:\n",
    "            [\n",
    "                {'dwi_series': ['scan1.nii', 'scan2.nii'], \n",
    "                 'rpe_dwi_series': ['scan3.nii', 'scan4.nii'],\n",
    "                 'rpe_b0': [],\n",
    "                 'dwi_series_pedir': 'j'}\n",
    "            ]\n",
    "            \n",
    "            When there is a PEPolar fieldmap\n",
    "            [\n",
    "             {\n",
    "              'dwi_series': ['scan1.nii', 'scan2.nii'],\n",
    "              'rpe_dwi_series': [],\n",
    "              'rpe_b0: ['fmap_scan.nii'],\n",
    "              'dwi_series_pedir': 'j'\n",
    "             }\n",
    "            ]\n",
    "            \n",
    "            When two different PE directions each have their own fieldmaps\n",
    "            [\n",
    "             {\n",
    "              'dwi_series': ['scan1.nii', 'scan2.nii'],\n",
    "              'rpe_dwi_series': [],\n",
    "              'rpe_b0: ['fmap_scan.nii'],\n",
    "              'dwi_series_pedir': 'j'\n",
    "             },\n",
    "             {\n",
    "              'dwi_series': ['scan3.nii', 'scan4.nii'],\n",
    "              'rpe_dwi_series': [],\n",
    "              'rpe_b0: ['fmap_scan2.nii'],\n",
    "              'dwi_series_pedir': 'j-'\n",
    "             }\n",
    "            ]\n",
    "            \n",
    "        NOTE: the pre-hmc steps, such as denoising, will only be run within warped space\n",
    "        groups \n",
    "            \n",
    "            \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # For doc-building\n",
    "    if layout is None:\n",
    "        return [{'dwi_series':dwi_series,\n",
    "                 'rpe_series':[],\n",
    "                 'rpe_b0':[],\n",
    "                 'dwi_series_pedir': 'j'}]\n",
    "\n",
    "    # For each DWI, figure out its PE dir and whether or not it was listed in\n",
    "    # an IntendedFor field in a fieldmap sidecar. Make a list of\n",
    "    # (filename, PE dir, fmap_file)\n",
    "    parsed_dwis = []\n",
    "    for ref_file in dwi_files:\n",
    "        metadata = layout.get_metadata(ref_file)\n",
    "\n",
    "        # Find fieldmaps. Options: (epi only)\n",
    "        fmaps = []\n",
    "        fmap_file = ''\n",
    "\n",
    "        fmaps = layout.get_fieldmap(ref_file, return_list=True)\n",
    "        fmap_files = []\n",
    "        for fmap in fmaps:\n",
    "            if fmap['type'] == 'epi':\n",
    "                fmap_files.append(fmap['epi'])\n",
    "\n",
    "        num_fmaps = len(fmap_files)\n",
    "        if num_fmaps > 1:\n",
    "            print(\"Multiple field maps found for %s\", ref_file)\n",
    "        if num_fmaps >= 1:\n",
    "            fmap_file = fmap_files[0]\n",
    "        parsed_dwis.append(\n",
    "            (ref_file, metadata['PhaseEncodingDirection'], fmap_file))\n",
    "    \n",
    "    # If we're not combining, each DWI series is its own group\n",
    "    groups = []\n",
    "    if not combine_all_dwis:\n",
    "        for ref_file, pe_dir, fmap_file in parsed_dwis:\n",
    "            groups.append({\n",
    "                'dwi_series': [ref_file],\n",
    "                'rpe_series': [],\n",
    "                'rpe_b0': fmap_file,\n",
    "                'dwi_series_pedir': pe_dir\n",
    "            })\n",
    "        return groups\n",
    "\n",
    "    # group by warped space, defined by pe_dir and fmap\n",
    "    groups = defaultdict(list)\n",
    "    for ref_file, pe_dir, fmap in parsed_dwis:\n",
    "        groups[(pe_dir, fmap)].append(ref_file)\n",
    "        \n",
    "\n",
    "    # Which groups can be combined to do bidirectional pepolar?\n",
    "    complete_groups = []\n",
    "    group_keys = set(groups.keys())\n",
    "\n",
    "    while len(group_keys):\n",
    "        \n",
    "        key = group_keys.pop()\n",
    "        scan_list = groups[key]\n",
    "        pe_dir, fmap = key\n",
    "        pe_axis = pe_dir[0]\n",
    "        \n",
    "        if prefer_dedicated_fmaps:\n",
    "            matches = [k for k in group_keys if k[0][0] == pe_axis and fmap == k[1]]\n",
    "        else:\n",
    "            matches = [k for k in group_keys if k[0][0] == pe_axis]\n",
    "        num_matches = len(matches)\n",
    "        \n",
    "        if not num_matches == 1:\n",
    "            # Didn't find any reverse PE groups\n",
    "            #print(\"No matches found for %s\" % key)\n",
    "            complete_groups.append(\n",
    "                {'dwi_series': scan_list,\n",
    "                 'rpe_series': [],\n",
    "                 'rpe_b0': fmap,\n",
    "                 'dwi_series_pedir': pe_dir\n",
    "                })\n",
    "        else:\n",
    "            # Found a perfect match\n",
    "            match = matches[0]\n",
    "            match_scan_list = groups[match]\n",
    "            complete_groups.append( \n",
    "                {'dwi_series': scan_list,\n",
    "                 'rpe_series': match_scan_list,\n",
    "                 'rpe_b0': [],\n",
    "                 'dwi_series_pedir': pe_dir}\n",
    "            )\n",
    "            group_keys.discard(match)\n",
    "            print(\"Matched %s to %s\" % (match, key))\n",
    "\n",
    "    return complete_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I want to use the opposite phase-encoding DWI series to correct for susceptibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched ('j-', '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-AP_epi.nii.gz') to ('j', '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-PA_epi.nii.gz')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dwi_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.nii.gz'],\n",
       "  'rpe_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.nii.gz'],\n",
       "  'rpe_b0': [],\n",
       "  'dwi_series_pedir': 'j'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_fieldmap=False\n",
    "prefer_dedicated_fmaps=False\n",
    "combine_all_dwis=True\n",
    "\n",
    "group_by_fieldmaps(dwi_files, layout, ignore_fieldmap, prefer_dedicated_fmaps,\n",
    "                   combine_all_dwis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to use the files in the fmap directory, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dwi_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.nii.gz'],\n",
       "  'rpe_series': [],\n",
       "  'rpe_b0': '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-PA_epi.nii.gz',\n",
       "  'dwi_series_pedir': 'j'},\n",
       " {'dwi_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.nii.gz'],\n",
       "  'rpe_series': [],\n",
       "  'rpe_b0': '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-AP_epi.nii.gz',\n",
       "  'dwi_series_pedir': 'j-'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_fieldmap=False\n",
    "prefer_dedicated_fmaps=True\n",
    "combine_all_dwis=True\n",
    "\n",
    "group_by_fieldmaps(dwi_files, layout, ignore_fieldmap, prefer_dedicated_fmaps,\n",
    "                   combine_all_dwis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dwi_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55AP_dwi.nii.gz'],\n",
       "  'rpe_series': [],\n",
       "  'rpe_b0': '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-PA_epi.nii.gz',\n",
       "  'dwi_series_pedir': 'j'},\n",
       " {'dwi_series': ['/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/dwi/sub-tester_acq-HASC55PA_dwi.nii.gz'],\n",
       "  'rpe_series': [],\n",
       "  'rpe_b0': '/Users/mcieslak/projects/qsiprep/notebooks/DSCSDSI_BUDS/sub-tester/fmap/sub-tester_dir-AP_epi.nii.gz',\n",
       "  'dwi_series_pedir': 'j-'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_fieldmap=False\n",
    "prefer_dedicated_fmaps=True\n",
    "combine_all_dwis=False\n",
    "\n",
    "group_by_fieldmaps(dwi_files, layout, ignore_fieldmap, prefer_dedicated_fmaps,\n",
    "                   combine_all_dwis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
